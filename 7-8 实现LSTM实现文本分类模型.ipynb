{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''谋篇布局，先确定实现那些模块，每个模块都有哪些功能'''\n",
    "\n",
    "\n",
    "''' 构建计算图：LSTM模型：\n",
    "        embedding层\n",
    "        LSTM层\n",
    "        FC层\n",
    "        train_op\n",
    "        \n",
    "    训练流程代码：\n",
    "    数据集封装代码：\n",
    "        API: next_batch(batch_size)\n",
    "    词表封装：\n",
    "        API：sentence2id（text_sentence）:句子转换ID\n",
    "    类别封装：\n",
    "        API：category2id（text_category）:类别转ID\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)#tf中的print日志模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''7-10 超参数定义'''\n",
    "def get_default_params():\n",
    "    '''这个API可以帮助啊管理模型的所有参数，返回的是一个对象，里面的参数都可以通过对象。参数名字来使用'''\n",
    "    return tf.contrib.training.HParams(\n",
    "        num_embending_size = 16,#embending向量长度\n",
    "        num_timesteps = 50,#指定LSTM步长，一个centent里面有多少词语\n",
    "        num_lstm_nodes = [32,32],#lstm的size是多少\n",
    "        num_lstm_lays = 2,#层数  ，有两层每一层都有32个神经单元\n",
    "        num_fc_nodes = 32,#fc层神经单元数目\n",
    "        batch_size = 100,\n",
    "        clip_lstm_grads = 1.0,#控制梯度大小因为lstm很容易发生梯度爆炸（设置上限）和梯度消失（lr_rate解决）等问题\n",
    "        learning_rate = 0.001,   \n",
    "        num_word_threshold =  10#统计的额词频filter上限\n",
    "    )\n",
    "\n",
    "'''得到默认的参数配置'''\n",
    "hps = get_default_params()\n",
    "\n",
    "'''定义输入和输出文件'''\n",
    "train_file = 'cnews_data/cnews.train.seg.txt'\n",
    "val_file = 'cnews_data/cnews.val.seg.txt'\n",
    "test_file = 'cnews_data/cnews.test.seg.txt'\n",
    "vocab_file = 'cnews_data/cnews.covab.txt'\n",
    "category_file = 'cnews_data/cnews.category.txt'\n",
    "output_floder = 'cnews_data/run_text_rnn'\n",
    "\n",
    "if not os.path.exists(output_floder):\n",
    "    os.mkdir(output_floder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size:77311\n",
      "label: 时尚, id: 5\n"
     ]
    }
   ],
   "source": [
    "'''7-11 词表封装于类别封装'''\n",
    "class Vocab:\n",
    "    def __init__(self, filename, num_word_threshold):\n",
    "        '''读这个文件，将独处的文件的id放到map里面'''\n",
    "        '''私有变量，不能通过对象直接访问而是要通过函数去访问'''\n",
    "        self._word_to_id = {}\n",
    "        self._unk = -1 #单独给出\n",
    "        self._num_word_threshold = num_word_threshold\n",
    "        self._read_dict(filename)\n",
    "        \n",
    "    def _read_dict(self, filename):\n",
    "        '''把词转化成id'''\n",
    "        with open(filename,'r') as f:\n",
    "            for line in f:\n",
    "                word, frequence = line.strip('\\s\\r').split('\\t')\n",
    "                frequence = int(frequence)\n",
    "                if frequence < self._num_word_threshold:\n",
    "                     continue\n",
    "                else:\n",
    "                    idx = len(self. _word_to_id)\n",
    "                if word == '<UNK>':\n",
    "                    self._unk = idx\n",
    "                self._word_to_id[word] = idx\n",
    "    \n",
    "    def word_to_id(self, word):\n",
    "        '''句子切分的词在字典中不存在'''\n",
    "        return self._word_to_id.get(word, self._unk)\n",
    "    \n",
    "    #给类加一些成员函数:有时候会访问一些unk的id等\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return self._unk\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self._word_to_id)\n",
    "    \n",
    "    def centence_to_id(self, centence):\n",
    "        '''把centence转化为id'''\n",
    "        word_ids = [self.word_to_id(cur_word) for cur_word in centence.split()]#对句子用空格切分，然后用每一个词在字典中进行查询。但可能有些词并不存在\n",
    "        return word_ids\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class  CategoryDict:\n",
    "    def __init__(self,filename):\n",
    "        self._categroy_to_id = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                categroy = line.strip('\\r\\n')\n",
    "                idx = len(self._categroy_to_id)\n",
    "                self._categroy_to_id[categroy] = idx\n",
    "    \n",
    "    def category_to_id(self,categroy):\n",
    "        if not categroy in self._categroy_to_id:\n",
    "            raise Exception('%s is not in our category list' % categroy)\n",
    "        return self._categroy_to_id[categroy]\n",
    "        \n",
    "vocab = Vocab(vocab_file, hps.num_word_threshold)\n",
    "tf.logging.info('vocab_size:%d'%vocab.size())\n",
    "\n",
    "category_vocab = CategoryDict(category_file)\n",
    "test_str = '时尚'\n",
    "print('label: %s, id: %d' % (test_str,category_vocab.category_to_id(test_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
